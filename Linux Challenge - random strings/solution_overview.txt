FINAL UPDATE: 29 May
After the last update, I managed to get all the smarts of the script into one line by using tee and piping the output directly into grep.

UPDATE: 29 May
I have updated the script slightly, in doing so I've manage to remove the need for the temp file and loop as described below.
As such I've renamed the original script with a _old_v1 postfix, replaced it with the new version.
Essentially I took advantage of the head -c flag to limit the size of the data stream being put into the file, and as such the script no longer needs to loop around to check the file size as head -c restricts the size.

Welcome!
For my solution I've used the built-in linux tools available such as /dev/urandom, grep, tr, head and fold to accomplish the requirements.
I have attempted to explain everything in as much detail as possible, more comments are in the script itself too.
I may have over-commented, but hopefully this will aid the challenge reviewers.

Script Assumptions:
- The script can create and modify files in the local directory.
- The script will have read access to /dev/urandom
- The following programs are available, in the $PATH: grep, tr, fold, wc,  cat, head, echo
- 1MB is 1024KBs or 1,048,576 Bytes

Output:
After running the script there will be 3 files generated in the locate directory.
The default files created are: output.txt, sorted_output.txt and filtered_output.txt.

Summary:
Part 1:
I have attempted to make the script versatile by using variables for most of the instructions which are at the top of the script.
For example the output file names and the length of the chars per line is easily configurable by changing the relevant variable value at the top of the script.

The work is done in a while loop that checks the output file size each iteration and stops once the file limit is reached.
In the loop, a block of data is read from /dev/urandom then parsed into alphanumeric chars and modified to be the required length using the tools mentioned above. Details are in the scriptâ€™s comments.

Part 2:
To ensure the output file does not exceed the required limit, data is read into a temp file, which is then added to the output file. This prevents too much data being put into the output file. Prior to adding data from the temp file to the output file, the output file size is checked , if adding the data will exceed the size limit then only a portion of the data in the temp file is added. Note the temp file will always be significantly smaller than the size of the data block being read from /dev/urandom, since in the script tr strips all the non alphanumeric characters. I decided to read in blocks of data from /dev/urandom rather single lines, as processing one line at a time is very slow.

Part 3:
Once the output file is completed, I use the sort program to sort the file alphabetically, the default options keep the numeric leading lines first, which is my preference. The sorted output is put into a separate file.

Part 4:
Then I use grep with a simple regular expression to remove all lines with a leading 'a' or 'A'. This output is also put into a separate file.

Part 5:
The amount of lines removed is calculated with wc and printed to the terminal.
